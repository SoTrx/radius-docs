---
type: docs
title: "Concept: Collaboration for Developers and Operators"
linkTitle: Collaboration for Developers and Operators
description: IT organizations are increasingly sophisticated and increasingly specialized. Radius was designed to enable collaboration between developers and the operations teams, cloud center of excellence teams, FinOps teams, and platform engineering teams that support these developers. 
weight: 200
categories: "Concept"
---

## IT teams are increasingly specialized

Cloud computing is an increasingly central part of enterprise strategy, especially as more and more enterprises build cloud native applications as part of being competitive in their respective industries. Originally, development teams were built to mimic the structure of engineering teams at big Internet companies like Amazon Web Services and Microsoft. These teams, called DevOps teams, understood how to build services as developers as well as how to run those services in production as operators. For some enterprises, this model worked well because it prioritized operational requirements like service availability, request latency, and, in the event of outages, mean-time-to-recovery. For other enterprises, the DevOps model enabled them to move faster than ever before. Small DevOps teams worked independently from each other, each team making quick technical decisions for their individual service as part of getting to production quickly. "Fail Fast" was a mantra for these teams and, with an experimental mindset, they quickly adapted to outages and operational issues. The DevOps model worked, and for some enterprises, continues to work.

For some enterprises this model began to break down as they increased their adoption of the cloud. Every DevOps team was making different decisions about which cloud provider they'd use, how they'd store their code, how their build pipelines worked, what services they'd use for compute, how they'd maintain application state, how logging and observability worked, and more. Best practices for engineering and operations weren't effectively shared. Also, DevOps teams made different decisions about the scale of their resources, making it challenging or impossible for enterprises to optimize the cost of using the cloud. Finally, without consistent, verifiable security practices, security mistakes were getting made which, at their worst resulted in a loss of business and customer trust. These issues in operations, cost, and security needed to be addressed consistently across the enterprise.

At the same time, Kubernetes was an inflection point. Enterprises standardized on Kubernetes, and this was a good idea. Kubernetes provided consistent tooling that worked on any cloud, helping enterprises reduce their "lock in" with a particular cloud provider. An open governance model ensured that no single vendor controlled Kubernetes and the Kubernetes ecosystem. All of this was good. What wasn't working was trying to teach developers to be good Kubernetes operators. DevOps teams were already struggling with operations, cost, and security best practices. Kubernetes was complex and becoming increasingly more complex as it evolved. Some enterprises built abstraction layers on top of Kubernetes, simplifying the use of Kubernetes, but these abstractions were complex to maintain.

Faced with poor adherence to best practices and the increasing complexity of Kubernetes, Enterprises increased specialization in their IT organizations. Some created centralized architecture teams, with some control over the way teams build their cloud native applications. Other enterprises created specialized security teams (SecOps) and finance teams (FinOps) to manage security and cost of using the cloud. An emerging group was the Platform Engineering team, which took a product mindset to build consistent internal tools for use by development teams across the enterprise. These Platform Engineers wanted to build simple, self-service tools that automated provisioning and configuration of all the components and services that are part of building a cloud native application. This meant automatically provisioning code repositories, build pipelines, observability, and, increasingly, the Kubernetes environment.

## Enabling Collaboration

We learned that there weren't great tools for collaboration between IT organizations and the developers they were supporting. Collaboration between developers and operators required detailed coordination, resulting in back-and-forth manual processes that slow down development velocity. Most organizations resorted to building custom pipelines or ticketing systems for infrastructure deployments, but these only ease part of the pain without addressing the underlying manual processes. Teams needed a better way to collaborate with each other.

When we looked deeper we saw that developers were mostly focused on writing code that was containerized and deployed into a container orchestration system, like Kubernetes. These applications needed a variety of cloud services to operate, like caches, queues, key/value stores, databases, and API front ends. The DevOps experience had taught enterprises that trying to make their developers experts in all of these systems didn't work well. What we needed was a way to enable developers to focus on their application. We also needed a way for developers to use cloud services, like caches, without having to understand the operations, cost, and security nuances for setting up that cloud service. Furthermore, if the application was deployed to different cloud regions in different parts of the world, the configuration of the cloud resources, like the size of a cache, would likely be different; an enterprise might have more traffic in Europe than in North America. 

### Radius Environments and Recipes

We created Radius Environments to enable a separation of concerns between developers and the IT organizations supporting those developers. Developers would create their applications, wrapping them as containers. Platform Engineering teams would create Environments to run that containerized application. The environment would include the container runtime, caches, key/value stores, or any other services required by the containerized application. For applications deployed to multiple regions, there could be an Environment per region, enabling the configuration and size of specific cloud resources, like a Redis cache or MongoDB database, to be different in different cloud regions. Radius would take care of the work to put the containerized application into the Environment designed and allocated by the Platform Engineering team.

We still needed a way for a developer to specify that their application needed a cloud resource, like a cache. And we needed a way for that cache to be configured and deployed following enterprise requirements for operations, cost, and security. To support this, we created Radius Recipes. We used the term "recipe" because our Recipes were similar to other attempts to simplify the deployment of resources, but our Recipes did four things beyond most existing recipes.

First, Radius recipes were not executed by the developer or the developer's code. Deploying cloud resources shouldn't require the IT team to share their credentials for creating resources, like a Redis cache. Instead, Radius recipes would run using credentials specified by the Platform Engineering team, deploying cloud resources precisely as intended. We needed to support existing investments in deploying and managing cloud resources, and so we needed to be unopinionated about how recipes were written. Radius supports Terraform and Bicep recipes in our first release with the expectation that more frameworks will be supported in the future.

Second, we needed Recipes to be an aspect of the Environment. This enabled us to support requirements for a cache to be bigger in one cloud region, like Europe, than it was in a different cloud region, like North America. Doing this had an additional benefit: **Recipes enable enterprises to build multi-cloud applications**. With our design, an enterprise could create an Environment for an AWS region and a different Environment for an Azure region. The recipe to create a Redis cache in the AWS Environment might deploy Amazon Elasticache for Redis and the recipe in the Azure Environment might deploy Azure Cache for Redis. The developer's code would just call the Redis cache recipe, unaware of what underlying infrastructure was deployed to provide the cache.

Third, we learned that it was challenging for developers to connect their application to the cloud resources that were deployed to support their application. Developers had to understand how to get host names, user names, and passwords from their IT team after the resource was deployed. It was even more complicated if the developer had to provision and then use workload identities or managed identities. Recipes need to take care of connecting the application to the cloud resource automatically, and it needed to feel like magic.

Finally, Recipes needed to be configurable by enterprises and by the community. In our first release, Recipes are stored in container registries, which can be public or private. Enterprises can create their own recipes and the community can publish community recipes, written in Terraform or Bicep, to create resources like MongoDB Atlas databases, a Confluent Cloud Kafka cluster, and more. In the future we expect to support other Recipe locations, like GitHub repos.

### How it works

Applications will get the resources they need by calling recipes created by the platform engineering team. Recipes can be called from a Helm Chart or a Bicep file. We expect to support other application definition models in the future. 

During deployment, the recipes to support that application are executed. This results in provisioning cloud resources and those cloud resources being connected directly with the application. Deployment can happen using any CI/CD solution from GitHub to Argo CD. At the end of deployment the container is running in a container orchestration system, like Kubernetes, and all of the necessary cloud resources are deployed and ready. 

The Environment and Recipe model also works for DevOps teams. When we spoke with DevOps teams we learned that there were usually a small group of people with stronger expertise in creating and managing cloud resources. We'd expect these people to be the people creating Environments and Recipes for use by their team. 

## Part of Platform Engineering

We think of Radius as helping with one part of the bigger Platform Engineering endeavor. Radius provides Environments and Recipes to help ensure that cloud resources meet enterprise requirements for operations, cost, and security. We also think that the Radius Application Graph, described elsewhere, will help everyone visualize and reason about their applications. With these components we hope to help Platform Engineers build simple but powerful platforms for their developers to use while improving the collaboration between developers and the broader IT organization.